{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 23:46:43.004294: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-12 23:46:43.085875: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-12 23:46:43.085923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-12 23:46:43.090343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-12 23:46:43.111045: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-12 23:46:43.835898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrindo dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.float64(np.load(open('data/cnn/x.npy', 'rb')))\n",
    "y = np.int8(np.load(open('data/cnn/y.npy', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_one_hot = to_categorical(y, 3)\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 23:46:51.238579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.345003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.345040: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.348189: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 402, 2, 300)       150300    \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 201, 1, 300)       0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 60300)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 60300)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               6030100   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6180703 (23.58 MB)\n",
      "Trainable params: 6180703 (23.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 23:46:51.348258: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.348271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.689292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.689390: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.689399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 23:46:51.689443: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-12 23:46:51.689484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(Conv2D(300, (100, 5), activation='relu', input_shape=(501, 6, 1)))\n",
    "modelo.add(AveragePooling2D((2, 2)))\n",
    "\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(100, activation='relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(3, activation='softmax'))\n",
    "\n",
    "modelo.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 23:46:53.416459: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 23:46:54.241070: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-03-12 23:46:54.397048: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-12 23:46:55.710959: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3981149b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-12 23:46:55.710993: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-03-12 23:46:55.722017: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710301615.809801   83051 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - ETA: 0s - loss: 1.0523 - accuracy: 0.4478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelio/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 18s 59ms/step - loss: 1.0523 - accuracy: 0.4478 - val_loss: 1.0072 - val_accuracy: 0.4673\n",
      "Epoch 2/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 1.0069 - accuracy: 0.4721 - val_loss: 0.9968 - val_accuracy: 0.4867\n",
      "Epoch 3/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.9958 - accuracy: 0.4874 - val_loss: 0.9784 - val_accuracy: 0.5021\n",
      "Epoch 4/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.9792 - accuracy: 0.5045 - val_loss: 0.9579 - val_accuracy: 0.5250\n",
      "Epoch 5/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.9579 - accuracy: 0.5263 - val_loss: 0.9368 - val_accuracy: 0.5412\n",
      "Epoch 6/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.9418 - accuracy: 0.5415 - val_loss: 0.9179 - val_accuracy: 0.5546\n",
      "Epoch 7/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.9252 - accuracy: 0.5552 - val_loss: 0.9056 - val_accuracy: 0.5710\n",
      "Epoch 8/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.9089 - accuracy: 0.5670 - val_loss: 0.8715 - val_accuracy: 0.6003\n",
      "Epoch 9/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.8941 - accuracy: 0.5782 - val_loss: 0.8574 - val_accuracy: 0.6119\n",
      "Epoch 10/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.8789 - accuracy: 0.5906 - val_loss: 0.8351 - val_accuracy: 0.6263\n",
      "Epoch 11/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.8614 - accuracy: 0.5995 - val_loss: 0.8222 - val_accuracy: 0.6355\n",
      "Epoch 12/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.8519 - accuracy: 0.6076 - val_loss: 0.8150 - val_accuracy: 0.6442\n",
      "Epoch 13/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.8371 - accuracy: 0.6161 - val_loss: 0.7870 - val_accuracy: 0.6632\n",
      "Epoch 14/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.8256 - accuracy: 0.6255 - val_loss: 0.7849 - val_accuracy: 0.6620\n",
      "Epoch 15/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.8144 - accuracy: 0.6303 - val_loss: 0.7601 - val_accuracy: 0.6808\n",
      "Epoch 16/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.8079 - accuracy: 0.6336 - val_loss: 0.7640 - val_accuracy: 0.6750\n",
      "Epoch 17/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.7939 - accuracy: 0.6419 - val_loss: 0.7543 - val_accuracy: 0.6822\n",
      "Epoch 18/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.7847 - accuracy: 0.6474 - val_loss: 0.7224 - val_accuracy: 0.7090\n",
      "Epoch 19/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.7745 - accuracy: 0.6547 - val_loss: 0.7169 - val_accuracy: 0.7028\n",
      "Epoch 20/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.7634 - accuracy: 0.6611 - val_loss: 0.7016 - val_accuracy: 0.7208\n",
      "Epoch 21/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.7568 - accuracy: 0.6631 - val_loss: 0.6930 - val_accuracy: 0.7235\n",
      "Epoch 22/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.7487 - accuracy: 0.6691 - val_loss: 0.6805 - val_accuracy: 0.7231\n",
      "Epoch 23/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.7407 - accuracy: 0.6736 - val_loss: 0.6842 - val_accuracy: 0.7239\n",
      "Epoch 24/500\n",
      "234/234 [==============================] - 11s 49ms/step - loss: 0.7351 - accuracy: 0.6758 - val_loss: 0.6639 - val_accuracy: 0.7370\n",
      "Epoch 25/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.7297 - accuracy: 0.6813 - val_loss: 0.6514 - val_accuracy: 0.7419\n",
      "Epoch 26/500\n",
      "234/234 [==============================] - 12s 52ms/step - loss: 0.7239 - accuracy: 0.6811 - val_loss: 0.6527 - val_accuracy: 0.7443\n",
      "Epoch 27/500\n",
      "234/234 [==============================] - 12s 50ms/step - loss: 0.7190 - accuracy: 0.6845 - val_loss: 0.6443 - val_accuracy: 0.7517\n",
      "Epoch 28/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.7150 - accuracy: 0.6869 - val_loss: 0.6503 - val_accuracy: 0.7458\n",
      "Epoch 29/500\n",
      "234/234 [==============================] - 12s 52ms/step - loss: 0.7089 - accuracy: 0.6894 - val_loss: 0.6319 - val_accuracy: 0.7553\n",
      "Epoch 30/500\n",
      "234/234 [==============================] - 12s 50ms/step - loss: 0.7032 - accuracy: 0.6937 - val_loss: 0.6242 - val_accuracy: 0.7621\n",
      "Epoch 31/500\n",
      "234/234 [==============================] - 12s 50ms/step - loss: 0.6967 - accuracy: 0.6987 - val_loss: 0.6143 - val_accuracy: 0.7629\n",
      "Epoch 32/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6884 - accuracy: 0.7035 - val_loss: 0.6207 - val_accuracy: 0.7579\n",
      "Epoch 33/500\n",
      "234/234 [==============================] - 12s 53ms/step - loss: 0.6886 - accuracy: 0.6999 - val_loss: 0.6005 - val_accuracy: 0.7726\n",
      "Epoch 34/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.6835 - accuracy: 0.7057 - val_loss: 0.6030 - val_accuracy: 0.7707\n",
      "Epoch 35/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.6758 - accuracy: 0.7104 - val_loss: 0.6062 - val_accuracy: 0.7701\n",
      "Epoch 36/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.6716 - accuracy: 0.7118 - val_loss: 0.5924 - val_accuracy: 0.7782\n",
      "Epoch 37/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.6659 - accuracy: 0.7124 - val_loss: 0.5879 - val_accuracy: 0.7792\n",
      "Epoch 38/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.6623 - accuracy: 0.7152 - val_loss: 0.5851 - val_accuracy: 0.7797\n",
      "Epoch 39/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.6620 - accuracy: 0.7152 - val_loss: 0.5804 - val_accuracy: 0.7827\n",
      "Epoch 40/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.6586 - accuracy: 0.7182 - val_loss: 0.5818 - val_accuracy: 0.7819\n",
      "Epoch 41/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.6599 - accuracy: 0.7156 - val_loss: 0.5681 - val_accuracy: 0.7893\n",
      "Epoch 42/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6511 - accuracy: 0.7235 - val_loss: 0.5824 - val_accuracy: 0.7790\n",
      "Epoch 43/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6520 - accuracy: 0.7203 - val_loss: 0.5694 - val_accuracy: 0.7889\n",
      "Epoch 44/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.6453 - accuracy: 0.7250 - val_loss: 0.5588 - val_accuracy: 0.7957\n",
      "Epoch 45/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.6436 - accuracy: 0.7251 - val_loss: 0.5641 - val_accuracy: 0.7910\n",
      "Epoch 46/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6449 - accuracy: 0.7248 - val_loss: 0.5558 - val_accuracy: 0.7951\n",
      "Epoch 47/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.6423 - accuracy: 0.7267 - val_loss: 0.5512 - val_accuracy: 0.7959\n",
      "Epoch 48/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.6335 - accuracy: 0.7315 - val_loss: 0.5491 - val_accuracy: 0.7962\n",
      "Epoch 49/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.6348 - accuracy: 0.7291 - val_loss: 0.5430 - val_accuracy: 0.8021\n",
      "Epoch 50/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.6334 - accuracy: 0.7298 - val_loss: 0.5375 - val_accuracy: 0.8055\n",
      "Epoch 51/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.6261 - accuracy: 0.7337 - val_loss: 0.5344 - val_accuracy: 0.8016\n",
      "Epoch 52/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.6278 - accuracy: 0.7324 - val_loss: 0.5371 - val_accuracy: 0.8062\n",
      "Epoch 53/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.6189 - accuracy: 0.7355 - val_loss: 0.5273 - val_accuracy: 0.8072\n",
      "Epoch 54/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6208 - accuracy: 0.7350 - val_loss: 0.5285 - val_accuracy: 0.8054\n",
      "Epoch 55/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6184 - accuracy: 0.7369 - val_loss: 0.5373 - val_accuracy: 0.8056\n",
      "Epoch 56/500\n",
      "234/234 [==============================] - 15s 64ms/step - loss: 0.6160 - accuracy: 0.7373 - val_loss: 0.5244 - val_accuracy: 0.8113\n",
      "Epoch 57/500\n",
      "234/234 [==============================] - 13s 53ms/step - loss: 0.6143 - accuracy: 0.7414 - val_loss: 0.5165 - val_accuracy: 0.8131\n",
      "Epoch 58/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6135 - accuracy: 0.7407 - val_loss: 0.5250 - val_accuracy: 0.8085\n",
      "Epoch 59/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6119 - accuracy: 0.7402 - val_loss: 0.5221 - val_accuracy: 0.8114\n",
      "Epoch 60/500\n",
      "234/234 [==============================] - 13s 55ms/step - loss: 0.6074 - accuracy: 0.7414 - val_loss: 0.5132 - val_accuracy: 0.8162\n",
      "Epoch 61/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6101 - accuracy: 0.7417 - val_loss: 0.5167 - val_accuracy: 0.8123\n",
      "Epoch 62/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6066 - accuracy: 0.7434 - val_loss: 0.5236 - val_accuracy: 0.8094\n",
      "Epoch 63/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.6051 - accuracy: 0.7459 - val_loss: 0.5155 - val_accuracy: 0.8152\n",
      "Epoch 64/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.6016 - accuracy: 0.7444 - val_loss: 0.5150 - val_accuracy: 0.8119\n",
      "Epoch 65/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.5989 - accuracy: 0.7480 - val_loss: 0.5066 - val_accuracy: 0.8174\n",
      "Epoch 66/500\n",
      "234/234 [==============================] - 12s 51ms/step - loss: 0.5968 - accuracy: 0.7467 - val_loss: 0.5043 - val_accuracy: 0.8187\n",
      "Epoch 67/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5954 - accuracy: 0.7483 - val_loss: 0.5043 - val_accuracy: 0.8173\n",
      "Epoch 68/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5943 - accuracy: 0.7493 - val_loss: 0.5035 - val_accuracy: 0.8172\n",
      "Epoch 69/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5988 - accuracy: 0.7462 - val_loss: 0.5267 - val_accuracy: 0.8092\n",
      "Epoch 70/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5956 - accuracy: 0.7489 - val_loss: 0.5333 - val_accuracy: 0.7995\n",
      "Epoch 71/500\n",
      "234/234 [==============================] - 11s 48ms/step - loss: 0.5914 - accuracy: 0.7501 - val_loss: 0.5006 - val_accuracy: 0.8196\n",
      "Epoch 72/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5907 - accuracy: 0.7497 - val_loss: 0.5046 - val_accuracy: 0.8183\n",
      "Epoch 73/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5904 - accuracy: 0.7505 - val_loss: 0.4978 - val_accuracy: 0.8184\n",
      "Epoch 74/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5842 - accuracy: 0.7544 - val_loss: 0.4964 - val_accuracy: 0.8217\n",
      "Epoch 75/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.5878 - accuracy: 0.7523 - val_loss: 0.4972 - val_accuracy: 0.8244\n",
      "Epoch 76/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5884 - accuracy: 0.7528 - val_loss: 0.4905 - val_accuracy: 0.8232\n",
      "Epoch 77/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5840 - accuracy: 0.7541 - val_loss: 0.4981 - val_accuracy: 0.8167\n",
      "Epoch 78/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5878 - accuracy: 0.7524 - val_loss: 0.4938 - val_accuracy: 0.8197\n",
      "Epoch 79/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5869 - accuracy: 0.7523 - val_loss: 0.4908 - val_accuracy: 0.8211\n",
      "Epoch 80/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5779 - accuracy: 0.7553 - val_loss: 0.4858 - val_accuracy: 0.8250\n",
      "Epoch 81/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5813 - accuracy: 0.7548 - val_loss: 0.4904 - val_accuracy: 0.8231\n",
      "Epoch 82/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5788 - accuracy: 0.7570 - val_loss: 0.4875 - val_accuracy: 0.8242\n",
      "Epoch 83/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5774 - accuracy: 0.7572 - val_loss: 0.4967 - val_accuracy: 0.8190\n",
      "Epoch 84/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5778 - accuracy: 0.7568 - val_loss: 0.4831 - val_accuracy: 0.8265\n",
      "Epoch 85/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5747 - accuracy: 0.7584 - val_loss: 0.4834 - val_accuracy: 0.8264\n",
      "Epoch 86/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5787 - accuracy: 0.7570 - val_loss: 0.5003 - val_accuracy: 0.8162\n",
      "Epoch 87/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5779 - accuracy: 0.7577 - val_loss: 0.4969 - val_accuracy: 0.8229\n",
      "Epoch 88/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5739 - accuracy: 0.7595 - val_loss: 0.4887 - val_accuracy: 0.8250\n",
      "Epoch 89/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5740 - accuracy: 0.7590 - val_loss: 0.4853 - val_accuracy: 0.8249\n",
      "Epoch 90/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5729 - accuracy: 0.7581 - val_loss: 0.4838 - val_accuracy: 0.8261\n",
      "Epoch 91/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5732 - accuracy: 0.7588 - val_loss: 0.4761 - val_accuracy: 0.8295\n",
      "Epoch 92/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5721 - accuracy: 0.7608 - val_loss: 0.4981 - val_accuracy: 0.8205\n",
      "Epoch 93/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5689 - accuracy: 0.7593 - val_loss: 0.4726 - val_accuracy: 0.8305\n",
      "Epoch 94/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5678 - accuracy: 0.7631 - val_loss: 0.5077 - val_accuracy: 0.8129\n",
      "Epoch 95/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5696 - accuracy: 0.7619 - val_loss: 0.4797 - val_accuracy: 0.8277\n",
      "Epoch 96/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5643 - accuracy: 0.7608 - val_loss: 0.4770 - val_accuracy: 0.8264\n",
      "Epoch 97/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5651 - accuracy: 0.7631 - val_loss: 0.4695 - val_accuracy: 0.8298\n",
      "Epoch 98/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5625 - accuracy: 0.7626 - val_loss: 0.4882 - val_accuracy: 0.8211\n",
      "Epoch 99/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5678 - accuracy: 0.7611 - val_loss: 0.5024 - val_accuracy: 0.8116\n",
      "Epoch 100/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5647 - accuracy: 0.7625 - val_loss: 0.4752 - val_accuracy: 0.8292\n",
      "Epoch 101/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5672 - accuracy: 0.7601 - val_loss: 0.4758 - val_accuracy: 0.8303\n",
      "Epoch 102/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5696 - accuracy: 0.7610 - val_loss: 0.4744 - val_accuracy: 0.8305\n",
      "Epoch 103/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5601 - accuracy: 0.7653 - val_loss: 0.4732 - val_accuracy: 0.8283\n",
      "Epoch 104/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.5677 - accuracy: 0.7614 - val_loss: 0.4713 - val_accuracy: 0.8331\n",
      "Epoch 105/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5602 - accuracy: 0.7641 - val_loss: 0.4716 - val_accuracy: 0.8291\n",
      "Epoch 106/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5613 - accuracy: 0.7641 - val_loss: 0.4811 - val_accuracy: 0.8233\n",
      "Epoch 107/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5635 - accuracy: 0.7620 - val_loss: 0.4677 - val_accuracy: 0.8328\n",
      "Epoch 108/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5624 - accuracy: 0.7645 - val_loss: 0.4786 - val_accuracy: 0.8284\n",
      "Epoch 109/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5547 - accuracy: 0.7669 - val_loss: 0.4645 - val_accuracy: 0.8289\n",
      "Epoch 110/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5539 - accuracy: 0.7684 - val_loss: 0.4682 - val_accuracy: 0.8300\n",
      "Epoch 111/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5609 - accuracy: 0.7645 - val_loss: 0.4726 - val_accuracy: 0.8290\n",
      "Epoch 112/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5573 - accuracy: 0.7659 - val_loss: 0.4744 - val_accuracy: 0.8264\n",
      "Epoch 113/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.5614 - accuracy: 0.7653 - val_loss: 0.4651 - val_accuracy: 0.8343\n",
      "Epoch 114/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5531 - accuracy: 0.7673 - val_loss: 0.4633 - val_accuracy: 0.8327\n",
      "Epoch 115/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5549 - accuracy: 0.7653 - val_loss: 0.4718 - val_accuracy: 0.8286\n",
      "Epoch 116/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5563 - accuracy: 0.7676 - val_loss: 0.4713 - val_accuracy: 0.8317\n",
      "Epoch 117/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5542 - accuracy: 0.7672 - val_loss: 0.4641 - val_accuracy: 0.8350\n",
      "Epoch 118/500\n",
      "234/234 [==============================] - 10s 43ms/step - loss: 0.5508 - accuracy: 0.7692 - val_loss: 0.4643 - val_accuracy: 0.8335\n",
      "Epoch 119/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5542 - accuracy: 0.7667 - val_loss: 0.4690 - val_accuracy: 0.8324\n",
      "Epoch 120/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5514 - accuracy: 0.7682 - val_loss: 0.4623 - val_accuracy: 0.8344\n",
      "Epoch 121/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5526 - accuracy: 0.7684 - val_loss: 0.4573 - val_accuracy: 0.8342\n",
      "Epoch 122/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5504 - accuracy: 0.7682 - val_loss: 0.4650 - val_accuracy: 0.8331\n",
      "Epoch 123/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5547 - accuracy: 0.7666 - val_loss: 0.4668 - val_accuracy: 0.8310\n",
      "Epoch 124/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5523 - accuracy: 0.7685 - val_loss: 0.4596 - val_accuracy: 0.8344\n",
      "Epoch 125/500\n",
      "234/234 [==============================] - 11s 47ms/step - loss: 0.5525 - accuracy: 0.7694 - val_loss: 0.4622 - val_accuracy: 0.8357\n",
      "Epoch 126/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5460 - accuracy: 0.7696 - val_loss: 0.4604 - val_accuracy: 0.8344\n",
      "Epoch 127/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5526 - accuracy: 0.7679 - val_loss: 0.4590 - val_accuracy: 0.8336\n",
      "Epoch 128/500\n",
      "234/234 [==============================] - 11s 46ms/step - loss: 0.5472 - accuracy: 0.7696 - val_loss: 0.4556 - val_accuracy: 0.8374\n",
      "Epoch 129/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5510 - accuracy: 0.7706 - val_loss: 0.4568 - val_accuracy: 0.8350\n",
      "Epoch 130/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5496 - accuracy: 0.7702 - val_loss: 0.4608 - val_accuracy: 0.8348\n",
      "Epoch 131/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5504 - accuracy: 0.7700 - val_loss: 0.4615 - val_accuracy: 0.8350\n",
      "Epoch 132/500\n",
      "234/234 [==============================] - 10s 44ms/step - loss: 0.5435 - accuracy: 0.7716 - val_loss: 0.4647 - val_accuracy: 0.8309\n",
      "Epoch 133/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5462 - accuracy: 0.7706 - val_loss: 0.4648 - val_accuracy: 0.8295\n",
      "Epoch 134/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5482 - accuracy: 0.7712 - val_loss: 0.4687 - val_accuracy: 0.8287\n",
      "Epoch 135/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5429 - accuracy: 0.7741 - val_loss: 0.4554 - val_accuracy: 0.8361\n",
      "Epoch 136/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5499 - accuracy: 0.7678 - val_loss: 0.4576 - val_accuracy: 0.8315\n",
      "Epoch 137/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5475 - accuracy: 0.7715 - val_loss: 0.4596 - val_accuracy: 0.8348\n",
      "Epoch 138/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5457 - accuracy: 0.7716 - val_loss: 0.4657 - val_accuracy: 0.8291\n",
      "Epoch 139/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5464 - accuracy: 0.7707 - val_loss: 0.4609 - val_accuracy: 0.8316\n",
      "Epoch 140/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5470 - accuracy: 0.7728 - val_loss: 0.4666 - val_accuracy: 0.8299\n",
      "Epoch 141/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5434 - accuracy: 0.7717 - val_loss: 0.4616 - val_accuracy: 0.8316\n",
      "Epoch 142/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5413 - accuracy: 0.7708 - val_loss: 0.4589 - val_accuracy: 0.8325\n",
      "Epoch 143/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5393 - accuracy: 0.7750 - val_loss: 0.4576 - val_accuracy: 0.8328\n",
      "Epoch 144/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5403 - accuracy: 0.7724 - val_loss: 0.4527 - val_accuracy: 0.8334\n",
      "Epoch 145/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5398 - accuracy: 0.7741 - val_loss: 0.4599 - val_accuracy: 0.8341\n",
      "Epoch 146/500\n",
      "234/234 [==============================] - 11s 45ms/step - loss: 0.5440 - accuracy: 0.7705 - val_loss: 0.4575 - val_accuracy: 0.8342\n",
      "Epoch 147/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5379 - accuracy: 0.7761 - val_loss: 0.4566 - val_accuracy: 0.8340\n",
      "Epoch 148/500\n",
      "234/234 [==============================] - 10s 45ms/step - loss: 0.5394 - accuracy: 0.7742 - val_loss: 0.4536 - val_accuracy: 0.8371\n",
      "Epoch 148: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f3c447a4670>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs/cnn/\")\n",
    "earlystop_cb = EarlyStopping(monitor='val_accuracy', patience=20, min_delta=0.001, verbose=True)\n",
    "modelcheckpoint_cb = ModelCheckpoint('/mnt/c/Users/aurel/OneDrive/Documentos/Projetos/tradingPredictor/models/CNNmodel5.h5', 'val_accuracy', save_best_only=True)\n",
    "\n",
    "modelo.fit(\n",
    "    x,\n",
    "    y_one_hot,\n",
    "    shuffle=True, \n",
    "    epochs=500,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback, earlystop_cb, modelcheckpoint_cb]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
