{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 22:41:29.593957: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 22:41:29.637532: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 22:41:29.637585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 22:41:29.639057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 22:41:29.645950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 22:41:30.422418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrindo dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.float64(np.load(open('data/x.npy', 'rb')))\n",
    "y = np.int8(np.load(open('data/y.npy', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_one_hot = to_categorical(y, 3)\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 22:42:54.704847: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13571 (53.01 KB)\n",
      "Trainable params: 13571 (53.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(LSTM(32, input_shape=(3006, 1)))\n",
    "modelo.add(Dense(256, activation=\"relu\"))\n",
    "modelo.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "modelo.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 22:43:02.084962: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-03-11 22:43:02.446610: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6bf01717f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-11 22:43:02.446667: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-03-11 22:43:02.474107: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710211382.603681  439798 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 56s 230ms/step - loss: 1.0807 - accuracy: 0.3900 - val_loss: 1.0781 - val_accuracy: 0.4002\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelio/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 48s 206ms/step - loss: 1.0762 - accuracy: 0.3991 - val_loss: 1.0762 - val_accuracy: 0.3990\n",
      "Epoch 3/200\n",
      "234/234 [==============================] - 51s 220ms/step - loss: 1.0758 - accuracy: 0.3995 - val_loss: 1.0769 - val_accuracy: 0.4003\n",
      "Epoch 4/200\n",
      "234/234 [==============================] - 50s 215ms/step - loss: 1.0749 - accuracy: 0.4022 - val_loss: 1.0751 - val_accuracy: 0.3973\n",
      "Epoch 5/200\n",
      "234/234 [==============================] - 50s 215ms/step - loss: 1.0743 - accuracy: 0.4010 - val_loss: 1.0755 - val_accuracy: 0.4043\n",
      "Epoch 6/200\n",
      "234/234 [==============================] - 50s 212ms/step - loss: 1.0737 - accuracy: 0.4055 - val_loss: 1.0754 - val_accuracy: 0.4049\n",
      "Epoch 7/200\n",
      "234/234 [==============================] - 49s 208ms/step - loss: 1.0725 - accuracy: 0.4077 - val_loss: 1.0731 - val_accuracy: 0.4084\n",
      "Epoch 8/200\n",
      "234/234 [==============================] - 52s 222ms/step - loss: 1.0714 - accuracy: 0.4065 - val_loss: 1.0716 - val_accuracy: 0.4169\n",
      "Epoch 9/200\n",
      "234/234 [==============================] - 50s 216ms/step - loss: 1.0694 - accuracy: 0.4139 - val_loss: 1.0690 - val_accuracy: 0.4157\n",
      "Epoch 10/200\n",
      "234/234 [==============================] - 50s 212ms/step - loss: 1.0670 - accuracy: 0.4182 - val_loss: 1.0675 - val_accuracy: 0.4189\n",
      "Epoch 11/200\n",
      "234/234 [==============================] - 50s 212ms/step - loss: 1.0641 - accuracy: 0.4189 - val_loss: 1.0633 - val_accuracy: 0.4309\n",
      "Epoch 12/200\n",
      "234/234 [==============================] - 50s 213ms/step - loss: 1.0619 - accuracy: 0.4230 - val_loss: 1.0591 - val_accuracy: 0.4293\n",
      "Epoch 13/200\n",
      "234/234 [==============================] - 53s 225ms/step - loss: 1.0572 - accuracy: 0.4321 - val_loss: 1.0528 - val_accuracy: 0.4479\n",
      "Epoch 14/200\n",
      "234/234 [==============================] - 51s 217ms/step - loss: 1.0559 - accuracy: 0.4350 - val_loss: 1.0551 - val_accuracy: 0.4372\n",
      "Epoch 15/200\n",
      "234/234 [==============================] - 48s 203ms/step - loss: 1.0525 - accuracy: 0.4398 - val_loss: 1.0494 - val_accuracy: 0.4496\n",
      "Epoch 16/200\n",
      "234/234 [==============================] - 48s 206ms/step - loss: 1.0430 - accuracy: 0.4537 - val_loss: 1.0376 - val_accuracy: 0.4656\n",
      "Epoch 17/200\n",
      "234/234 [==============================] - 47s 203ms/step - loss: 1.0350 - accuracy: 0.4632 - val_loss: 1.0302 - val_accuracy: 0.4705\n",
      "Epoch 18/200\n",
      "234/234 [==============================] - 50s 213ms/step - loss: 1.0300 - accuracy: 0.4686 - val_loss: 1.0310 - val_accuracy: 0.4700\n",
      "Epoch 19/200\n",
      "234/234 [==============================] - 49s 209ms/step - loss: 1.0254 - accuracy: 0.4701 - val_loss: 1.0250 - val_accuracy: 0.4716\n",
      "Epoch 20/200\n",
      "234/234 [==============================] - 47s 201ms/step - loss: 1.0226 - accuracy: 0.4731 - val_loss: 1.0171 - val_accuracy: 0.4813\n",
      "Epoch 21/200\n",
      "234/234 [==============================] - 47s 202ms/step - loss: 1.0287 - accuracy: 0.4688 - val_loss: 1.0183 - val_accuracy: 0.4845\n",
      "Epoch 22/200\n",
      "234/234 [==============================] - 47s 201ms/step - loss: 1.0091 - accuracy: 0.4907 - val_loss: 1.0082 - val_accuracy: 0.4936\n",
      "Epoch 23/200\n",
      "234/234 [==============================] - 51s 216ms/step - loss: 0.9999 - accuracy: 0.4996 - val_loss: 0.9985 - val_accuracy: 0.5032\n",
      "Epoch 24/200\n",
      "234/234 [==============================] - 50s 212ms/step - loss: 0.9964 - accuracy: 0.5023 - val_loss: 0.9940 - val_accuracy: 0.5064\n",
      "Epoch 25/200\n",
      "234/234 [==============================] - 48s 204ms/step - loss: 0.9879 - accuracy: 0.5106 - val_loss: 0.9845 - val_accuracy: 0.5103\n",
      "Epoch 26/200\n",
      "234/234 [==============================] - 49s 210ms/step - loss: 0.9796 - accuracy: 0.5178 - val_loss: 0.9822 - val_accuracy: 0.5141\n",
      "Epoch 27/200\n",
      "234/234 [==============================] - 79s 337ms/step - loss: 0.9804 - accuracy: 0.5158 - val_loss: 1.0192 - val_accuracy: 0.4760\n",
      "Epoch 28/200\n",
      "234/234 [==============================] - 87s 372ms/step - loss: 0.9950 - accuracy: 0.5003 - val_loss: 0.9835 - val_accuracy: 0.5111\n",
      "Epoch 29/200\n",
      "234/234 [==============================] - 57s 243ms/step - loss: 0.9800 - accuracy: 0.5160 - val_loss: 0.9843 - val_accuracy: 0.5149\n",
      "Epoch 30/200\n",
      "234/234 [==============================] - 47s 203ms/step - loss: 0.9685 - accuracy: 0.5246 - val_loss: 0.9729 - val_accuracy: 0.5185\n",
      "Epoch 31/200\n",
      "234/234 [==============================] - 50s 213ms/step - loss: 0.9634 - accuracy: 0.5278 - val_loss: 0.9595 - val_accuracy: 0.5268\n",
      "Epoch 32/200\n",
      "234/234 [==============================] - 53s 228ms/step - loss: 0.9553 - accuracy: 0.5334 - val_loss: 0.9554 - val_accuracy: 0.5390\n",
      "Epoch 33/200\n",
      "234/234 [==============================] - 49s 208ms/step - loss: 0.9497 - accuracy: 0.5387 - val_loss: 0.9492 - val_accuracy: 0.5377\n",
      "Epoch 34/200\n",
      "234/234 [==============================] - 57s 245ms/step - loss: 0.9414 - accuracy: 0.5435 - val_loss: 0.9531 - val_accuracy: 0.5302\n",
      "Epoch 35/200\n",
      "234/234 [==============================] - 199s 852ms/step - loss: 0.9358 - accuracy: 0.5453 - val_loss: 0.9389 - val_accuracy: 0.5467\n",
      "Epoch 36/200\n",
      "234/234 [==============================] - 171s 731ms/step - loss: 0.9299 - accuracy: 0.5492 - val_loss: 0.9299 - val_accuracy: 0.5523\n",
      "Epoch 37/200\n",
      "234/234 [==============================] - 237s 1s/step - loss: 0.9248 - accuracy: 0.5514 - val_loss: 0.9265 - val_accuracy: 0.5495\n",
      "Epoch 38/200\n",
      "234/234 [==============================] - 173s 739ms/step - loss: 0.9221 - accuracy: 0.5523 - val_loss: 0.9283 - val_accuracy: 0.5527\n",
      "Epoch 39/200\n",
      "234/234 [==============================] - 213s 913ms/step - loss: 0.9192 - accuracy: 0.5556 - val_loss: 0.9210 - val_accuracy: 0.5477\n",
      "Epoch 40/200\n",
      "234/234 [==============================] - 205s 875ms/step - loss: 0.9135 - accuracy: 0.5585 - val_loss: 0.9160 - val_accuracy: 0.5592\n",
      "Epoch 41/200\n",
      "234/234 [==============================] - 226s 963ms/step - loss: 0.9132 - accuracy: 0.5567 - val_loss: 0.9182 - val_accuracy: 0.5599\n",
      "Epoch 42/200\n",
      "234/234 [==============================] - 133s 571ms/step - loss: 0.9078 - accuracy: 0.5617 - val_loss: 0.9119 - val_accuracy: 0.5615\n",
      "Epoch 43/200\n",
      "234/234 [==============================] - 49s 210ms/step - loss: 0.9075 - accuracy: 0.5614 - val_loss: 0.9055 - val_accuracy: 0.5603\n",
      "Epoch 44/200\n",
      "234/234 [==============================] - 47s 201ms/step - loss: 0.9041 - accuracy: 0.5632 - val_loss: 0.9095 - val_accuracy: 0.5608\n",
      "Epoch 45/200\n",
      "234/234 [==============================] - 48s 203ms/step - loss: 0.9017 - accuracy: 0.5621 - val_loss: 0.9113 - val_accuracy: 0.5531\n",
      "Epoch 46/200\n",
      "234/234 [==============================] - 47s 203ms/step - loss: 0.8978 - accuracy: 0.5654 - val_loss: 0.9015 - val_accuracy: 0.5638\n",
      "Epoch 47/200\n",
      "234/234 [==============================] - 51s 217ms/step - loss: 0.8963 - accuracy: 0.5644 - val_loss: 0.9060 - val_accuracy: 0.5667\n",
      "Epoch 48/200\n",
      "234/234 [==============================] - 50s 216ms/step - loss: 0.8940 - accuracy: 0.5675 - val_loss: 0.9036 - val_accuracy: 0.5613\n",
      "Epoch 49/200\n",
      "234/234 [==============================] - 146s 628ms/step - loss: 0.8924 - accuracy: 0.5660 - val_loss: 0.9069 - val_accuracy: 0.5618\n",
      "Epoch 50/200\n",
      "234/234 [==============================] - 159s 680ms/step - loss: 0.8931 - accuracy: 0.5665 - val_loss: 0.8932 - val_accuracy: 0.5697\n",
      "Epoch 51/200\n",
      "234/234 [==============================] - 159s 680ms/step - loss: 0.8902 - accuracy: 0.5689 - val_loss: 0.9013 - val_accuracy: 0.5630\n",
      "Epoch 52/200\n",
      "234/234 [==============================] - 156s 670ms/step - loss: 0.8876 - accuracy: 0.5686 - val_loss: 0.8939 - val_accuracy: 0.5656\n",
      "Epoch 53/200\n",
      "234/234 [==============================] - 162s 683ms/step - loss: 0.8865 - accuracy: 0.5686 - val_loss: 0.8995 - val_accuracy: 0.5652\n",
      "Epoch 54/200\n",
      "234/234 [==============================] - 162s 694ms/step - loss: 0.8845 - accuracy: 0.5697 - val_loss: 0.8890 - val_accuracy: 0.5676\n",
      "Epoch 55/200\n",
      "234/234 [==============================] - 159s 680ms/step - loss: 0.8903 - accuracy: 0.5670 - val_loss: 0.8901 - val_accuracy: 0.5662\n",
      "Epoch 56/200\n",
      "234/234 [==============================] - 156s 668ms/step - loss: 0.8815 - accuracy: 0.5699 - val_loss: 0.8948 - val_accuracy: 0.5664\n",
      "Epoch 57/200\n",
      "234/234 [==============================] - 159s 681ms/step - loss: 0.8816 - accuracy: 0.5712 - val_loss: 0.8883 - val_accuracy: 0.5630\n",
      "Epoch 58/200\n",
      "234/234 [==============================] - 158s 678ms/step - loss: 0.8813 - accuracy: 0.5695 - val_loss: 0.8909 - val_accuracy: 0.5638\n",
      "Epoch 59/200\n",
      "234/234 [==============================] - 159s 683ms/step - loss: 0.8805 - accuracy: 0.5728 - val_loss: 0.8895 - val_accuracy: 0.5692\n",
      "Epoch 60/200\n",
      "234/234 [==============================] - 159s 682ms/step - loss: 0.8788 - accuracy: 0.5687 - val_loss: 0.8837 - val_accuracy: 0.5729\n",
      "Epoch 61/200\n",
      "234/234 [==============================] - 155s 665ms/step - loss: 0.8798 - accuracy: 0.5693 - val_loss: 0.8939 - val_accuracy: 0.5622\n",
      "Epoch 62/200\n",
      "234/234 [==============================] - 159s 682ms/step - loss: 0.8772 - accuracy: 0.5720 - val_loss: 0.8867 - val_accuracy: 0.5620\n",
      "Epoch 63/200\n",
      "234/234 [==============================] - 156s 667ms/step - loss: 0.8758 - accuracy: 0.5712 - val_loss: 0.8876 - val_accuracy: 0.5674\n",
      "Epoch 64/200\n",
      "234/234 [==============================] - 155s 654ms/step - loss: 0.8759 - accuracy: 0.5739 - val_loss: 0.8835 - val_accuracy: 0.5634\n",
      "Epoch 65/200\n",
      "234/234 [==============================] - 55s 234ms/step - loss: 0.8762 - accuracy: 0.5714 - val_loss: 0.8951 - val_accuracy: 0.5652\n",
      "Epoch 66/200\n",
      "234/234 [==============================] - 49s 210ms/step - loss: 0.8745 - accuracy: 0.5708 - val_loss: 0.8828 - val_accuracy: 0.5691\n",
      "Epoch 67/200\n",
      "234/234 [==============================] - 49s 211ms/step - loss: 0.8733 - accuracy: 0.5730 - val_loss: 0.8749 - val_accuracy: 0.5741\n",
      "Epoch 68/200\n",
      "234/234 [==============================] - 48s 205ms/step - loss: 0.8730 - accuracy: 0.5725 - val_loss: 0.8790 - val_accuracy: 0.5723\n",
      "Epoch 69/200\n",
      "234/234 [==============================] - 49s 208ms/step - loss: 0.8711 - accuracy: 0.5743 - val_loss: 0.8793 - val_accuracy: 0.5686\n",
      "Epoch 70/200\n",
      "234/234 [==============================] - 51s 219ms/step - loss: 0.8730 - accuracy: 0.5713 - val_loss: 0.8816 - val_accuracy: 0.5719\n",
      "Epoch 71/200\n",
      "234/234 [==============================] - 52s 224ms/step - loss: 0.8687 - accuracy: 0.5738 - val_loss: 0.8801 - val_accuracy: 0.5704\n",
      "Epoch 72/200\n",
      "234/234 [==============================] - 50s 214ms/step - loss: 0.8700 - accuracy: 0.5736 - val_loss: 0.8776 - val_accuracy: 0.5709\n",
      "Epoch 73/200\n",
      "234/234 [==============================] - 48s 204ms/step - loss: 0.8714 - accuracy: 0.5734 - val_loss: 0.8746 - val_accuracy: 0.5739\n",
      "Epoch 74/200\n",
      "234/234 [==============================] - 48s 206ms/step - loss: 0.8689 - accuracy: 0.5741 - val_loss: 0.8782 - val_accuracy: 0.5702\n",
      "Epoch 75/200\n",
      "234/234 [==============================] - 52s 222ms/step - loss: 0.8675 - accuracy: 0.5721 - val_loss: 0.8781 - val_accuracy: 0.5680\n",
      "Epoch 76/200\n",
      "234/234 [==============================] - 52s 222ms/step - loss: 0.8680 - accuracy: 0.5739 - val_loss: 0.8785 - val_accuracy: 0.5751\n",
      "Epoch 77/200\n",
      "234/234 [==============================] - 47s 200ms/step - loss: 0.8671 - accuracy: 0.5751 - val_loss: 0.8833 - val_accuracy: 0.5731\n",
      "Epoch 78/200\n",
      "234/234 [==============================] - 47s 201ms/step - loss: 0.8672 - accuracy: 0.5769 - val_loss: 0.8771 - val_accuracy: 0.5687\n",
      "Epoch 79/200\n",
      "234/234 [==============================] - 50s 213ms/step - loss: 0.8679 - accuracy: 0.5733 - val_loss: 0.8752 - val_accuracy: 0.5718\n",
      "Epoch 80/200\n",
      "234/234 [==============================] - 52s 222ms/step - loss: 0.8658 - accuracy: 0.5734 - val_loss: 0.8812 - val_accuracy: 0.5684\n",
      "Epoch 81/200\n",
      "234/234 [==============================] - 51s 218ms/step - loss: 0.8660 - accuracy: 0.5734 - val_loss: 0.8811 - val_accuracy: 0.5637\n",
      "Epoch 82/200\n",
      "234/234 [==============================] - 47s 199ms/step - loss: 0.8662 - accuracy: 0.5731 - val_loss: 0.8719 - val_accuracy: 0.5747\n",
      "Epoch 83/200\n",
      "234/234 [==============================] - 47s 201ms/step - loss: 0.8643 - accuracy: 0.5757 - val_loss: 0.8801 - val_accuracy: 0.5705\n",
      "Epoch 84/200\n",
      "234/234 [==============================] - 50s 212ms/step - loss: 0.8653 - accuracy: 0.5741 - val_loss: 0.8748 - val_accuracy: 0.5716\n",
      "Epoch 85/200\n",
      "234/234 [==============================] - 53s 227ms/step - loss: 0.8635 - accuracy: 0.5757 - val_loss: 0.8774 - val_accuracy: 0.5685\n",
      "Epoch 86/200\n",
      "234/234 [==============================] - 49s 210ms/step - loss: 0.8645 - accuracy: 0.5746 - val_loss: 0.8780 - val_accuracy: 0.5685\n",
      "Epoch 87/200\n",
      "234/234 [==============================] - 47s 202ms/step - loss: 0.8654 - accuracy: 0.5727 - val_loss: 0.8767 - val_accuracy: 0.5661\n",
      "Epoch 88/200\n",
      "234/234 [==============================] - 48s 203ms/step - loss: 0.8653 - accuracy: 0.5734 - val_loss: 0.8753 - val_accuracy: 0.5693\n",
      "Epoch 89/200\n",
      "234/234 [==============================] - 50s 214ms/step - loss: 0.8637 - accuracy: 0.5730 - val_loss: 0.8745 - val_accuracy: 0.5727\n",
      "Epoch 90/200\n",
      "234/234 [==============================] - 53s 225ms/step - loss: 0.8623 - accuracy: 0.5743 - val_loss: 0.8747 - val_accuracy: 0.5708\n",
      "Epoch 91/200\n",
      "234/234 [==============================] - 48s 205ms/step - loss: 0.8628 - accuracy: 0.5750 - val_loss: 0.8713 - val_accuracy: 0.5721\n",
      "Epoch 92/200\n",
      "234/234 [==============================] - 47s 200ms/step - loss: 0.8638 - accuracy: 0.5738 - val_loss: 0.8679 - val_accuracy: 0.5761\n",
      "Epoch 93/200\n",
      "234/234 [==============================] - 47s 200ms/step - loss: 0.8616 - accuracy: 0.5760 - val_loss: 0.8676 - val_accuracy: 0.5743\n",
      "Epoch 94/200\n",
      "234/234 [==============================] - 51s 216ms/step - loss: 0.8615 - accuracy: 0.5763 - val_loss: 0.8826 - val_accuracy: 0.5670\n",
      "Epoch 95/200\n",
      "234/234 [==============================] - 53s 225ms/step - loss: 0.8625 - accuracy: 0.5753 - val_loss: 0.8756 - val_accuracy: 0.5709\n",
      "Epoch 96/200\n",
      "234/234 [==============================] - 52s 222ms/step - loss: 0.8614 - accuracy: 0.5749 - val_loss: 0.8709 - val_accuracy: 0.5729\n",
      "Epoch 97/200\n",
      "234/234 [==============================] - 47s 200ms/step - loss: 0.8625 - accuracy: 0.5750 - val_loss: 0.8720 - val_accuracy: 0.5777\n",
      "Epoch 98/200\n",
      "234/234 [==============================] - 48s 206ms/step - loss: 0.8611 - accuracy: 0.5740 - val_loss: 0.8736 - val_accuracy: 0.5739\n",
      "Epoch 99/200\n",
      "234/234 [==============================] - 51s 220ms/step - loss: 0.8602 - accuracy: 0.5760 - val_loss: 0.8721 - val_accuracy: 0.5717\n",
      "Epoch 100/200\n",
      "234/234 [==============================] - 51s 220ms/step - loss: 0.8605 - accuracy: 0.5770 - val_loss: 0.8713 - val_accuracy: 0.5716\n",
      "Epoch 101/200\n",
      "234/234 [==============================] - 50s 215ms/step - loss: 0.8598 - accuracy: 0.5775 - val_loss: 0.8699 - val_accuracy: 0.5803\n",
      "Epoch 102/200\n",
      "234/234 [==============================] - 47s 200ms/step - loss: 0.8585 - accuracy: 0.5780 - val_loss: 0.8688 - val_accuracy: 0.5737\n",
      "Epoch 103/200\n",
      "234/234 [==============================] - 48s 207ms/step - loss: 0.8596 - accuracy: 0.5747 - val_loss: 0.8701 - val_accuracy: 0.5743\n",
      "Epoch 104/200\n",
      "234/234 [==============================] - 51s 220ms/step - loss: 0.8599 - accuracy: 0.5734 - val_loss: 0.8668 - val_accuracy: 0.5791\n",
      "Epoch 105/200\n",
      "234/234 [==============================] - 52s 222ms/step - loss: 0.8593 - accuracy: 0.5770 - val_loss: 0.8688 - val_accuracy: 0.5747\n",
      "Epoch 106/200\n",
      "234/234 [==============================] - 50s 214ms/step - loss: 0.8586 - accuracy: 0.5766 - val_loss: 0.8729 - val_accuracy: 0.5727\n",
      "Epoch 107/200\n",
      "234/234 [==============================] - 48s 203ms/step - loss: 0.8593 - accuracy: 0.5749 - val_loss: 0.8652 - val_accuracy: 0.5793\n",
      "Epoch 108/200\n",
      "234/234 [==============================] - 49s 210ms/step - loss: 0.8573 - accuracy: 0.5760 - val_loss: 0.8737 - val_accuracy: 0.5737\n",
      "Epoch 109/200\n",
      "234/234 [==============================] - 53s 225ms/step - loss: 0.8597 - accuracy: 0.5747 - val_loss: 0.8681 - val_accuracy: 0.5754\n",
      "Epoch 110/200\n",
      "234/234 [==============================] - 52s 224ms/step - loss: 0.8828 - accuracy: 0.5646 - val_loss: 0.8835 - val_accuracy: 0.5697\n",
      "Epoch 111/200\n",
      "234/234 [==============================] - 48s 203ms/step - loss: 0.8616 - accuracy: 0.5763 - val_loss: 0.8708 - val_accuracy: 0.5760\n",
      "Epoch 112/200\n",
      "234/234 [==============================] - 47s 199ms/step - loss: 0.8588 - accuracy: 0.5768 - val_loss: 0.8676 - val_accuracy: 0.5769\n",
      "Epoch 113/200\n",
      "234/234 [==============================] - 50s 212ms/step - loss: 0.8568 - accuracy: 0.5780 - val_loss: 0.8679 - val_accuracy: 0.5764\n",
      "Epoch 114/200\n",
      "234/234 [==============================] - 52s 223ms/step - loss: 0.8573 - accuracy: 0.5781 - val_loss: 0.8739 - val_accuracy: 0.5743\n",
      "Epoch 115/200\n",
      "234/234 [==============================] - 53s 225ms/step - loss: 0.8558 - accuracy: 0.5769 - val_loss: 0.8656 - val_accuracy: 0.5718\n",
      "Epoch 116/200\n",
      "234/234 [==============================] - 48s 205ms/step - loss: 0.8574 - accuracy: 0.5767 - val_loss: 0.8679 - val_accuracy: 0.5744\n",
      "Epoch 117/200\n",
      "234/234 [==============================] - 48s 203ms/step - loss: 0.8558 - accuracy: 0.5780 - val_loss: 0.8638 - val_accuracy: 0.5797\n",
      "Epoch 118/200\n",
      "234/234 [==============================] - 51s 217ms/step - loss: 0.8553 - accuracy: 0.5762 - val_loss: 0.8646 - val_accuracy: 0.5777\n",
      "Epoch 119/200\n",
      "234/234 [==============================] - 53s 225ms/step - loss: 0.8566 - accuracy: 0.5762 - val_loss: 0.8707 - val_accuracy: 0.5756\n",
      "Epoch 120/200\n",
      "234/234 [==============================] - 51s 219ms/step - loss: 0.8576 - accuracy: 0.5753 - val_loss: 0.8688 - val_accuracy: 0.5721\n",
      "Epoch 121/200\n",
      "234/234 [==============================] - 46s 197ms/step - loss: 0.8555 - accuracy: 0.5766 - val_loss: 0.8702 - val_accuracy: 0.5717\n",
      "Epoch 121: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6d23f99e70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs/lstm/\")\n",
    "earlystop_cb = EarlyStopping(monitor='val_accuracy', patience=20, min_delta=0.001, verbose=True)\n",
    "modelcheckpoint_cb = ModelCheckpoint('models/LSTMmodel.h5', 'val_accuracy', save_best_only=True)\n",
    "\n",
    "modelo.fit(\n",
    "    x,\n",
    "    y_one_hot,\n",
    "    shuffle=True, \n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback, earlystop_cb, modelcheckpoint_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo.save('models/tf-cnn-model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
